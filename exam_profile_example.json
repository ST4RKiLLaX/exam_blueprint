{
  "profile_id": "example_cert_2026",
  // REQUIRED: Unique identifier for this profile. Use lowercase with underscores.
  // Convention: {exam_abbreviation}_{year}
  // This ID is referenced by agents and knowledge bases.
  
  "name": "Example Certification",
  // REQUIRED: Human-readable name displayed in UI dropdowns and profile cards.
  
  "description": "Example Professional Certification - demonstrates all available fields and their usage patterns for developer reference.",
  // REQUIRED: Brief description explaining the exam's focus, level, and approach.
  // Used in UI tooltips and profile selection screens.
  
  "question_types": [
    // REQUIRED: Array defining question format patterns.
    // Each type represents a different way to frame the stem and options.
    // Agents use these to vary question structure and avoid repetitive patterns.
    {
      "id": "definition",
      // REQUIRED: Unique identifier within this profile.
      // Used internally to select question type during generation.
      
      "difficulty_level": "1",
      // REQUIRED: References a global difficulty level ID.
      // Must match a level defined in the global difficulty registry.
      // Level 1 = Recall/Understanding, Level 2 = Application/Analysis, Level 3 = Evaluation/Judgment
      
      "phrase": "What is the definition of",
      // REQUIRED: The exact phrasing pattern used in the question stem.
      
      "guidance": "Test direct recall of facts, terms, and definitions. Stem should be short and unambiguous. Distractors should be plausible terms/concepts but clearly incorrect if the test-taker knows the definition."
      // REQUIRED: Instructions to the AI agent on how to construct questions of this type.
    },
    {
      "id": "identification",
      "difficulty_level": "1",
      "phrase": "Which of the following is an example of",
      "guidance": "Test recognition and identification of concepts. Present a concept and ask for correct example or characteristic. One option clearly matches the definition, others are related but incorrect."
    },
    {
      "id": "scenario_apply",
      "difficulty_level": "2",
      "phrase": "In this scenario, which principle applies",
      "guidance": "Present a realistic scenario requiring application of knowledge. Test whether candidate can map the situation to the correct principle, control category, or process step. Options can be partially correct, but one best fits the scenario constraints."
    },
    {
      "id": "troubleshoot",
      "difficulty_level": "2",
      "phrase": "What is the MOST likely cause of",
      "guidance": "Present a problem scenario testing analysis skills. Can the candidate identify root cause from symptoms? Require understanding concepts well enough to diagnose issues in context."
    },
    {
      "id": "comparative",
      "difficulty_level": "3",
      "phrase": "Which is BEST/MOST appropriate?",
      "guidance": "Frame options as competing alternatives with varying degrees of correctness. The correct answer should represent the optimal choice given typical enterprise constraints, resource availability, and risk tolerance. All options should be technically valid but differ in effectiveness, scalability, or alignment with governance principles."
    },
    {
      "id": "sequential",
      "difficulty_level": "3",
      "phrase": "What should be done FIRST?",
      "guidance": "Frame options as dependent steps in a workflow or process. The correct answer should reflect proper sequencing based on dependencies (e.g., assessment before implementation), risk priority (address highest impact first), authority requirements (get approval before acting), or governance principles (policy before procedure)."
    },
    {
      "id": "risk_identification",
      "difficulty_level": "3",
      "phrase": "What is the PRIMARY risk?",
      "guidance": "Frame the scenario around a potential security issue or business decision. Options should present different risks, threats, or concerns. The correct answer identifies the most significant risk from a business impact perspective, not just technical severity. Prefer business/strategic risks over technical symptoms."
    },
    {
      "id": "control_selection",
      "difficulty_level": "3",
      "phrase": "Which control MOST effectively addresses the issue?",
      "guidance": "Frame options as different security controls, countermeasures, or mitigation strategies. The correct answer should be the most effective control considering enterprise scale, sustainability, cost-effectiveness, and risk reduction. Avoid selecting controls based solely on technical sophistication."
    },
    {
      "id": "exception",
      "difficulty_level": "3",
      "phrase": "When would this NOT apply?",
      "guidance": "Use sparingly. Frame options as different scenarios or conditions. The correct answer should identify a clearly defined exception based on scope, context, authority boundaries, or applicability limits. Avoid trick questions or artificial ambiguity."
    }
  ],
  
  "domains": [
    // REQUIRED: Array defining knowledge domains or exam sections.
    // Used for organizing knowledge bases and providing domain-specific context to agents.
    // The two-stage retrieval system uses these to query domain-specific KBs.
    {
      "id": "domain_one",
      // REQUIRED: Unique identifier for this domain.
      // Convention: Use lowercase with underscores, avoid special characters.
      // Referenced when assigning KBs and during question generation routing.
      
      "name": "Domain One: Example Area",
      // REQUIRED: Human-readable domain name.
      // Displayed in UI filters, KB assignment screens, and question metadata.
      
      "keywords": [
        // REQUIRED: Array of keywords/phrases that trigger this domain during retrieval.
        // Used by semantic search to match user queries and topics to domains.
        // Include: core concepts, common abbreviations, related technologies,
        // typical terminology, and professional jargon.
        // More keywords improve retrieval accuracy but may cause overlap with other domains.
        "governance",
        "policy",
        "compliance",
        "risk management",
        "regulatory",
        "framework",
        "standard",
        "audit",
        "accountability",
        "responsibility"
      ],
      
      "priority": "high"
      // OPTIONAL: Used for weighting or emphasis during generation.
      // Values: "high", "medium", "low"
      // High-priority domains may receive more questions or be emphasized in agent prompts.
      // Not currently used in core logic but reserved for future enhancements.
    },
    {
      "id": "domain_two",
      "name": "Domain Two: Technical Controls",
      "keywords": [
        "encryption",
        "cryptography",
        "authentication",
        "authorization",
        "access control",
        "network security",
        "firewall",
        "ids",
        "ips",
        "vpn"
      ],
      "priority": "medium"
    },
    {
      "id": "domain_three",
      "name": "Domain Three: Operations",
      "keywords": [
        "incident response",
        "monitoring",
        "logging",
        "siem",
        "forensics",
        "disaster recovery",
        "business continuity",
        "backup",
        "change management"
      ],
      "priority": "medium"
    }
  ],
  
  "reasoning_modes": [
    // REQUIRED: Array defining different analytical frameworks or thinking styles.
    // Agents rotate among these modes to create variety in question approach.
    // Each mode represents a different lens through which to evaluate a scenario.
    {
      "id": "governance",
      // REQUIRED: Unique identifier for this reasoning mode.
      
      "name": "Governance",
      // REQUIRED: Human-readable name for this mode.
      
      "description": "Use a policy and compliance lens. Frame questions in terms of governance requirements, organizational policy, regulatory compliance, management responsibility, and authority. Questions should emphasize who has the right to decide, what policies apply, and accountability structures. Prefer answers that establish or follow proper authorization chains."
      // REQUIRED: Detailed instructions on how this mode should influence question design.
      // Tells the agent what perspective to take, what factors to emphasize,
      // and what type of reasoning the test-taker should apply.
    },
    {
      "id": "risk_based",
      "name": "Risk-Based Thinking",
      "description": "Use risk management principles. Frame questions using the chain: threat → vulnerability → impact → control → residual risk. Questions should emphasize likelihood and impact assessment, risk prioritization, risk tolerance, and cost-benefit analysis. The correct answer should reflect defensible risk-based decision making."
    },
    {
      "id": "process",
      "name": "Process-Oriented",
      "description": "Use lifecycle or phase-based thinking. Frame questions around process stages (plan, design, implement, monitor), implementation phases, sequential workflows, or structured methodologies. Questions should test understanding of dependencies, proper sequencing, and phase-appropriate activities."
    },
    {
      "id": "comparative_analysis",
      "name": "Comparative Analysis",
      "description": "Use trade-off evaluation. Frame questions around comparing different approaches, technologies, or strategies. Highlight advantages and disadvantages in enterprise contexts. Questions should force weighing multiple valid options against realistic constraints like budget, time, expertise, compatibility, and organizational maturity."
    }
  ],
  
  "difficulty_profile": {
    // REQUIRED: Difficulty distribution settings for this exam profile.
    // Controls which difficulty levels are enabled and their distribution.
    // Uses the three-layer architecture: global levels → question types tagged with levels → profile settings
    
    "enabled_levels": ["1", "2", "3"],
    // REQUIRED: Array of level IDs that are enabled for this profile.
    // Must reference level IDs from the global difficulty registry (defined in code).
    // At least one level must be enabled.
    // Users can toggle these in the UI when generating questions.
    
    "weights": {
      "1": 0.15,
      "2": 0.35,
      "3": 0.50
    },
    // REQUIRED: Weights controlling difficulty distribution.
    // Keys must match enabled_levels. Values are relative weights (don't need to sum to 1.0).
    // System normalizes these at runtime based on enabled levels.
    // Example: 15% Level 1, 35% Level 2, 50% Level 3 questions.
    // If user disables Level 1, weights auto-renormalize to {2: 0.41, 3: 0.59}
    
    "display_names": {
      "1": "Foundational Knowledge",
      "2": "Scenario Application",
      "3": "Professional Judgment"
    }
    // OPTIONAL: Custom display names for levels in this profile's UI.
    // Allows exam-specific terminology while maintaining global level standards.
    // If omitted, uses global level names (Recall/Understanding, Application/Analysis, Evaluation/Judgment).
  },
  // Notes on the new difficulty system:
  // - Global difficulty levels (1, 2, 3) are defined in code and shared across all exams
  // - Each question_type declares its cognitive level via "difficulty_level" field
  // - This difficulty_profile section configures weights and enabled levels per exam
  // - Two-stage selection: pick level by weights → pick question type within level
  // - Prevents question type count from biasing distribution
  
  "kb_structure": {
    // REQUIRED: Defines how knowledge bases are organized and queried for this profile.
    // These settings control the two-stage retrieval system used during question generation.
    
    "priority_kb_flag": "is_priority_kb",
    // REQUIRED: The field name used to identify priority/outline knowledge bases.
    // Priority KBs are queried first to establish topic structure before domain-specific retrieval.
    // Must match the boolean field in knowledge_bases.json.
    // Example: An exam outline or domain structure document would be marked as priority.
    
    "outline_type": "outline",
    // REQUIRED: The KB type value that indicates outline/structure documents.
    // Used in conjunction with priority_kb_flag to identify high-level organizational KBs.
    // These KBs provide the "table of contents" for the exam.
    
    "domain_type": "cbk"
    // REQUIRED: The KB type value that indicates domain-specific content.
    // These KBs contain detailed subject matter for each domain.
    // After querying priority KBs, the system queries domain-specific KBs based on the topic.
    // Common values: "cbk" (Common Body of Knowledge), "domain", "content", "material"
  },
  
  "guidance_suffix": "Ensure the question tests understanding at the appropriate depth for this certification level. The correct answer should reflect professional judgment, industry best practices, and real-world constraints. Avoid testing pure memorization, tool-specific configurations, or overly technical implementation details unless those are core to the certification's focus.",
  // REQUIRED: Additional instructions appended to every generation prompt.
  // Use this for exam-wide quality standards, philosophical approach, or constraints.
  // This is sent to the agent every time, so keep it concise but comprehensive.
  // Common uses: set difficulty level, emphasize certain principles, prohibit certain question types.
  
  "global_constraints": [
    // OPTIONAL: Array of specific rules or prohibitions for question generation.
    // These are more specific than guidance_suffix and act as quality control filters.
    // Not currently passed directly to agents but used for validation and documentation.
    "Prefer management authority over technical staff action when both are viable",
    "Assume enterprise-scale environments with standard governance structures",
    "Avoid vendor-specific product names, tool configurations, or version-specific features",
    "Ensure incorrect options reflect common professional mistakes, not obvious errors",
    "Controls should not precede assessment unless explicitly justified in the scenario"
  ],
  
  "usage": {
    // AUTO-GENERATED: Usage tracking for this profile.
    // Updated automatically by the system when agents or KBs reference this profile.
    // Do not manually edit - these values are computed and may be overwritten.
    
    "agents_count": 0,
    // Count of agents currently using this profile
    
    "kb_count": 0,
    // Count of knowledge bases assigned to this profile
    
    "agent_ids": [],
    // Array of agent IDs that reference this profile
    
    "kb_ids": []
    // Array of KB IDs assigned to this profile
  }
}
